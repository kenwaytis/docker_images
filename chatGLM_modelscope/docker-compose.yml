version: '3.8'
services:
  chatGLM:
    build: 
      context: .
      dockerfile: Dockerfile
      args:
        HTTP_PROXY: ${HTTP_PROXY}
    image: paidax/chatglm-6b-0.1
    container_name: chatglm
    runtime: nvidia
    ports:
      - 9523:9523
    command: tail -f /dev/null